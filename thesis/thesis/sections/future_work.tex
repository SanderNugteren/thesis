\section{Conclusion and future work}

In this paper it is shown that the model can capture the preconditions and
implications of actions. Also, since the model keeps a list of probable actors
around for \texttt{obj}, \texttt{subj} and \texttt{dat},
it can capture how these character archetypes would act in a story. Because of the
way the model is queried however, these are not rules set in stone. A princess
might not murder often, but there is a small chance that it does happen. In
fact, a story where the princess would murder could be considered original, if
handled well (with a logical justifaction arising from a set of more probable
events).

As briefly alluded to in the Model section, the next step is to let a planning
algorithm generate stories based on the obtained rule probabilities. A possible
approach has been outlined in that section, but perhaps even more sophisticated
planning is possible, either mixing probable and improbable events on the fly,
or designing stories with more probable and improbable parts.

The current approach uses variables to keep track of how many times a certain
character was involved with an action and in what way. In a fairy tale context
this works, since characters are usually not named but are just known by their
archetype (the princess, the king, the witch, etc.). One could argue that this
is just a unique feature of fairy tales, but other genres have certain conventions
too. For example, in film noir, there are also certain stock characters (the
hard-boiled detective, the mysterious nightclub singer), but usually these are
known by their names, not by their archetype. An extension of this algorithm
could have characters with attributes, and let the probabilities be dependent on
the character attributes instead of the characters themselves.

Another way this approach could be extended is to get some more sophisticated
natural language parsing being done. The stories the current model was trained
on were manually annotated, but using only the information available from the
story synopses available from Wikipedia or similar sources. The challenges here
would be parsing the natural language found in the synopses, recognize the
entities, their properties and how they interact.
This would still be easier to accomplish than feeding the algorithm the complete
story as it might be found in a book, since then the algorithm would also have
to filter out which parts are actually rellevant for the plot.
Of course, the representation obtained automatically would not be as rich as a
humanly annotated one, but with sufficient stories it should be possible to fill
in the gaps, even without modifying the current way of probability computation
for rules.
